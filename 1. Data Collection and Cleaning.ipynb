{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect county level demographic data and presidential election results from the four following election years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2008, 2012, 2016, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presidential election data is obtained from the <a href=\"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ\">MIT Election Data + Science Lab</a>.\n",
    "\n",
    ">> MIT Election Data and Science Lab, 2018, \"County Presidential Election Returns 2000-2020\", https://doi.org/10.7910/DVN/VOQCHQ, Harvard Dataverse, V12, UNF:6:KNR0/XNVzJC+RnAqIx5Z1Q== [fileUNF] \n",
    "\n",
    "\n",
    "Demographic data is obtained from the IPUMS's National Historical Geographic Information System (NHGIS). Specifically, we use their data coming from the US American Community Survey 5-year estimates. For election year $n$, we use the survey that covers the range $n-2$ to $n+2$. The variable names and their meanings can be found in the codebooks that accompony the NHGIS datasets. Throughout the cleaning process, we replace the original variable codes with mnemonically appropriate names. \n",
    "\n",
    ">>Steven Manson, Jonathan Schroeder, David Van Riper, Katherine Knowles, Tracy Kugler, Finn Roberts, and Steven Ruggles. IPUMS National Historical Geographic Information System: Version 18.0 [dataset]. Minneapolis, MN: IPUMS. 2023. http://doi.org/10.18128/D050.V18.0\n",
    "\n",
    "\n",
    "Geographic data for all counties is taken directly from the pygris package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygris as pyg\n",
    "import area_unit_conversion as auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing all data, creating dictionaries for each type of data, and splitting data according to years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import election data\n",
    "raw_election_data = pd.read_csv(\"raw_data/MIT_election_data/president_2000-2020_by_county.csv\")\n",
    "\n",
    "# Create dictionaries to hold data by year\n",
    "election = {}\n",
    "demographic = {}\n",
    "geographic = {}\n",
    "data = {}\n",
    "\n",
    "#  Add to dictionaries with { key=year : value =  data for that year}\n",
    "# e.g. demographic[2008] gives access to the 2008 demographic data\n",
    "# e.g. election[2008] gives access to the 2008 election data\n",
    "for year in years:\n",
    "    # Add election data\n",
    "    election[year] = raw_election_data[ raw_election_data.year == year ]\n",
    "    # Add demographic data\n",
    "    demographic[year] = pd.read_csv(f\"raw_data/NHGIS/general/general_{year - 2}_{year + 2}.csv\",encoding = 'unicode_escape')\n",
    "    # Add geographic data\n",
    "    if year<2014:  \n",
    "        geographic[year] = pyg.counties(cb=True,cache=True, year=year+2)\n",
    "    else:\n",
    "        geographic[year] = pyg.counties(cb=True,cache=True, year=year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary with (keys= column names , values= list of row indices in that column with NaN)\n",
    "def find_nan(df):\n",
    "    return { feature : df[feature][df[feature].isna()].index.to_list() for feature in df.columns.to_list() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of row indices which have zeros in the specified column\n",
    "def find_zeros(df, column):\n",
    "    return df[ df[column]==0 ].index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find NHGIS codes for race-demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list of race-demographics related variables depending on the input year.\n",
    "def race_dict(year):\n",
    "    if (year == 2020):\n",
    "        return ['AQYHE','AQYIE','AQYJE','AQYKE','AQYLE','AQYME','AQYNE']\n",
    "    if (year == 2016):\n",
    "        return ['AJ6OE','AJ6PE','AJ6QE','AJ6RE','AJ6SE','AJ6TE','AJ6UE']\n",
    "    if (year == 2012):\n",
    "        return ['ABK1E','ABK2E','ABK3E','ABK4E','ABK5E','ABK6E','ABK7E']\n",
    "    if (year == 2008):\n",
    "        return ['JVOE','JVPE','JVQE','JVRE','JVSE','JVTE','JVUE'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from square-meters to square-miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return round(auc.convert('m2','mi2',x),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find mismatched FIPS codes between a list different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fips_dropper(df_list):\n",
    "    #Make list of fips codes in each dataframe in df_list\n",
    "    fip_list = [ set(df['fips'].values) for df in df_list ]\n",
    "\n",
    "    #Compute the intersection of all the lists of fips codes\n",
    "    fip_common = fip_list[0]\n",
    "    for i in range(1,len(fip_list)):\n",
    "        fip_common = fip_common.intersection(fip_list[i])\n",
    "        \n",
    "    #Drop the non-common fips rows and sort by fips\n",
    "    for df in df_list:\n",
    "        rows_to_drop = [ j for j in range(len(df)) if df.loc[j,'fips'] not in fip_common ]\n",
    "        df.drop(index=rows_to_drop, inplace=True)\n",
    "        df.sort_values(by='fips',inplace=True,ignore_index=True)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Cleaning and merging functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Election Data Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def election_cleaner():\n",
    "    # Creates a list with all county FIP codes\n",
    "    list_of_fips = pd.read_csv(\"../data/RANDOM/fips2county.tsv\", sep=\"\\t\")\n",
    "    list_of_fips = list_of_fips[['CountyFIPS']]\n",
    "    \n",
    "    # Goes through each election year\n",
    "    for year in election:\n",
    "        # Resets index of each year from zero\n",
    "        election[year].reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        # Rename columns\n",
    "        election[year] = election[year].rename({'county_name':'county', 'county_fips':'fips', 'candidatevotes':'votes'}, axis='columns')\n",
    "        \n",
    "        # Creates a list of rows to drop\n",
    "        rows_to_drop = []\n",
    "        \n",
    "        # Find rows with missing FIP codes\n",
    "        missing_fips = find_nan(election[year])['fips']\n",
    "        rows_to_drop += missing_fips\n",
    "        \n",
    "        # Find rows with missing votes (totalvotes=0)\n",
    "        missing_votes = find_zeros(election[year], 'totalvotes')\n",
    "        rows_to_drop += missing_votes\n",
    "        \n",
    "        # Find rows corresponding to third parties\n",
    "        third_parties = election[year][ election[year]['party'] != 'DEMOCRAT'][ election[year]['party'] != 'REPUBLICAN'].index.to_list()\n",
    "        rows_to_drop += third_parties\n",
    "        \n",
    "        # Find rows with incorrect/nonexistent FIP codes\n",
    "        weird_fips = list(set(election[year]['fips'])-set(list_of_fips['CountyFIPS']))\n",
    "        weird_fips_rows = []\n",
    "        for i in range(len(election[year])):\n",
    "            if election[year].loc[i,'fips'] in weird_fips:\n",
    "                weird_fips_rows.append(i)\n",
    "        rows_to_drop += weird_fips_rows\n",
    "        \n",
    "        # Drop problematic rows and resets index\n",
    "        rows_to_drop = list(set(rows_to_drop))\n",
    "        election[year] = election[year].drop(rows_to_drop, axis=0)\n",
    "        election[year].reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        # Deal with 2020 election year, which requires combining different modes of voting\n",
    "        if year==2020:\n",
    "            df_temp = pd.DataFrame(columns=election[year].columns)  # new temp df\n",
    "            for row in range(len(election[year])):                  # go through each row of 2020 election\n",
    "                if ( election[year].loc[row,'mode'] == 'TOTAL'):    # if the mode is total, add row to temp df\n",
    "                    df_temp.loc[len(df_temp)] = election[year].loc[row].values\n",
    "                elif (election[year].loc[row, 'mode']=='SKIP'):     # if the mode is skip, skip that row\n",
    "                    continue\n",
    "                else:                                               # deal with non-total rows\n",
    "                    j = 0                                           # set a counter\n",
    "                    total_votes = 0                                 # new variable to keep track of cumulative sum\n",
    "                    while (election[year].loc[row+j,'fips']==election[year].loc[row,'fips'] ) and (election[year].loc[row+j,'party']==election[year].loc[row,'party']):\n",
    "                        total_votes += election[year].loc[row+j,'votes']\n",
    "                        if row+j> row:\n",
    "                            election[year].loc[row+j,'mode'] = 'SKIP'\n",
    "                        j = j + 1\n",
    "                    df_temp.loc[len(df_temp)] = election[year].loc[row].values\n",
    "                    df_temp.loc[len(df_temp)-1,'mode'] = 'TOTAL'\n",
    "                    df_temp.loc[len(df_temp)-1,'votes'] = total_votes\n",
    "            election[year] = df_temp\n",
    "        \n",
    "        # Calculate and add columns containing dem, repub, other votes\n",
    "        other_votes = [election[year].loc[2*i,'totalvotes']-election[year].loc[2*i,'votes']-election[year].loc[2*i+1,'votes'] for i in range(int(len(election[year])/2))]\n",
    "        repub_votes = [ election[year].loc[2*i+1,'votes'] for i in range(int(len(election[year])/2))]\n",
    "        repub = [2*i+1 for i in range(int(len(election[year])/2))]  # find republican rows (odd rows)\n",
    "        election[year] = election[year].drop(repub, axis=0)         # drop republican rows\n",
    "        election[year].reset_index(inplace=True,drop=True)          # reset index\n",
    "        election[year]['dem'] = election[year].votes                # add dem votes column\n",
    "        election[year]['repub'] = repub_votes                       # add repub votes column\n",
    "        election[year]['other'] = other_votes                       # add other votes column\n",
    "\n",
    "        # Cast FIPs as integers\n",
    "        election[year].fips = election[year].fips.astype(int)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        cols_to_drop = ['year', 'state', 'state_po', 'county', 'office', 'candidate', 'votes', 'party', 'version']\n",
    "        election[year] = election[year].drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    # Do a final row elimination, to keep only the rows that all election years have in common\n",
    "    final_fips_to_drop = list(set(election[2020].fips)-set.intersection(set(election[2008].fips),set(election[2012].fips),set(election[2016].fips),set(election[2020].fips)))\n",
    "    rows_to_drop = []\n",
    "    for year in election:\n",
    "        for fips in final_fips_to_drop:\n",
    "            if fips in election[year].fips.values:\n",
    "                election[year] = election[year].drop(election[year][ election[year].fips==fips ].index.to_list(), axis=0)\n",
    "                election[year].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic data cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_cleaner():\n",
    "    for year in years:\n",
    "        df = demographic[year]\n",
    "\n",
    "        #Drop all entries corresponding to Puerto Rico\n",
    "        df.drop(index = df.index[df['STATE'] == \"Puerto Rico\"].tolist(), inplace=True)\n",
    "        df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        #Fix the erroneous fips code for Connecticut (state code = 9) for the year 2020\n",
    "        if (year==2020):\n",
    "            for i in df.index[df['STATEFP'] == 9].tolist():\n",
    "                df.loc[i,'COUNTYFP'] //= 10\n",
    "\n",
    "        #Create the output dataframe; we do this here so we can get rid of columns in df\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df['fips'] = 1000* df['STATEFP'] + df['COUNTYFP']\n",
    "\n",
    "        #drop irrelevant columns (first 9) and margin-of-error columns in df\n",
    "        cols = list(df.columns)\n",
    "        cols_to_drop = cols[:9] + [c for c in cols if c[-1]=='M']\n",
    "        df.drop(inplace=True,columns=cols_to_drop)\n",
    "\n",
    "        #Remove last 3 digits from each column name in df; \n",
    "        #This is the only thing that varies by year.\n",
    "        cols = list(df.columns)\n",
    "        col_map = { cols[i] : (cols[i])[:-3] for i in range(len(cols)) }\n",
    "        df.rename(col_map, inplace = True, axis = 'columns')\n",
    "\n",
    "        #Rename and add some of the columns to the new df\n",
    "        col_names = [['AV0AA','pop_tot'],\n",
    "                    ['AV1AA','pop_male'],\n",
    "                    ['AV1AB','pop_female'],\n",
    "                    ['A35AA','hispanic'],\n",
    "                    ['B84AA','labor_total'],\n",
    "                    ['B84AB','labor_armed'],\n",
    "                    ['B84AD','labor_employed'],\n",
    "                    ['B84AE','labor_unemployed'],\n",
    "                    ['B79AA','income_median'],\n",
    "                    ['BD5AA','income_percapita'],\n",
    "                    ['CL6AA','income_poverty'],\n",
    "                    ['AT5AA','native_yes'],\n",
    "                    ['AT5AB','native_no'],\n",
    "                    ['AR5AA','houses_tot'],\n",
    "                    ['BS7AA','income_10'],\n",
    "                    ['BS7AB','income_10-15'],\n",
    "                    ['BS7AC','income_15-25'],\n",
    "                    ['BS7AD','income_25']\n",
    "                    ]\n",
    "\n",
    "        for i in range(len(col_names)):\n",
    "            new_df[col_names[i][1]] = df[col_names[i][0]]\n",
    "\n",
    "        #Add columns on marital status to new df\n",
    "        new_df['marital_single']  = df['BL1AA'] + df['BL1AG']\n",
    "        new_df['marital_married'] = df['BL1AC'] + df['BL1AI']\n",
    "        new_df['marital_sepdiv']  = df['BL1AD'] + df['BL1AF'] + df['BL1AJ'] + df['BL1AL']\n",
    "        new_df['marital_widow']   = df['BL1AE'] + df['BL1AK']\n",
    "\n",
    "        #Add columns on educational attainment\n",
    "        new_df['edu_low']  = df['B87AA'] + df['B87AB']\n",
    "        new_df['edu_mid']  = df['B87AC'] + df['B87AD'] + df['B87AE']\n",
    "        new_df['edu_high'] = df['B87AF'] + df['B87AG']\n",
    "\n",
    "        #Add columns on edu attainment by age\n",
    "        cols = list(df.columns)\n",
    "        edu = [['edu_low',0,1],\n",
    "            ['edu_mid',2,3,4],\n",
    "            ['edu_high',5,6]]\n",
    "        age = [['age_18',0,7,14],\n",
    "            ['age_45',21],\n",
    "            ['age_65',28]]\n",
    "        ind = cols.index('B91AA')\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                e = edu[i]\n",
    "                a = age[j]\n",
    "                name = e[0] + '_' + a[0]\n",
    "                new_df[name] = 0\n",
    "                for l in a[1:]:\n",
    "                        for m in e[1:]:\n",
    "                            c = cols[ind + l + m]\n",
    "                            new_df[name] += df[cols[ind + l + m]] + df[cols[ind + l + m + 35]]\n",
    "\n",
    "        #Next, let's bring in the data from the race-by-sex spreadsheet\n",
    "        s = f'../data/NHGIS/race_by_sex/race_by_sex_{year - 2}_{year + 2}.csv'\n",
    "        race_df = pd.read_csv(s,encoding='unicode_escape')\n",
    "\n",
    "        #Drop all entries corresponding to Puerto Rico\n",
    "        race_df.drop(index = race_df.index[race_df['STATE'] == \"Puerto Rico\"].tolist(), inplace=True)\n",
    "        race_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        #Create fips column to properly merge with df\n",
    "        race_df['fips'] = 1000* race_df['STATEA'] + race_df['COUNTYA']\n",
    "\n",
    "        #Sort df and race_df by fips code to ensure proper merging\n",
    "        race_df.sort_values(by='fips',inplace=True,ignore_index=True)\n",
    "        new_df.sort_values(by='fips',inplace=True,ignore_index=True)\n",
    "\n",
    "        #Check that the fips codes are all matched up\n",
    "        mismatches = [i for i in range(len(new_df)) if new_df.loc[i,'fips'] != race_df.loc[i,'fips']]\n",
    "        # print('Mismatches:', mismatches)\n",
    "\n",
    "        #Add race-by-sex data to new_df\n",
    "        sex = [['total','001'],\n",
    "                ['male','002'],\n",
    "                ['female','017']]\n",
    "        race = [['wht',race_dict(year)[0]],\n",
    "                ['blk',race_dict(year)[1]],\n",
    "                ['other'] + race_dict(year)[2:]]\n",
    "\n",
    "        for r in race:\n",
    "            for s in sex:\n",
    "                name = f'race_{r[0]}_{s[0]}'\n",
    "                new_df[name] = 0\n",
    "                for w in r[1:]:\n",
    "                    labl = w + s[1]\n",
    "                    new_df[name] += race_df[labl]\n",
    "\n",
    "        #This concludes the cleaning. Now, we return the cleaned dataframe to the demographic dictionary\n",
    "        demographic[year] = new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Data Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_cleaner():\n",
    "    for year in years:\n",
    "        # The last three years need updated column names and total area in sq-miles\n",
    "        if year!=2008:\n",
    "            # Rename columns for consistency\n",
    "            geographic[year] = geographic[year].rename({'STATEFP':'STATE', 'COUNTYFP':'COUNTY'}, axis='columns')\n",
    "            # Add columns for the total area in sqmiles      \n",
    "            geographic[year]['CENSUSAREA'] = list(map( f, geographic[year]['ALAND'] + geographic[year]['AWATER'] )) \n",
    "        # Add an fips code column\n",
    "        geographic[year]['fips'] = 1000 * geographic[year]['STATE'].astype(int) + geographic[year]['COUNTY'].astype(int)\n",
    "        # Return cleaned dataframe to dictionary\n",
    "        geographic[year] = geographic[year][['fips', 'CENSUSAREA']]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merger():\n",
    "    # Merge election, demo, and geo data for each year\n",
    "    for year in years:\n",
    "        elec, demo, geo = fips_dropper([ election[year], demographic[year], geographic[year] ])\n",
    "        data[year] = (elec.merge(demo,on='fips',how='outer')).merge(geo,on='fips',how='outer')\n",
    "        \n",
    "    # Drop rows that do not appear in all four years\n",
    "    for i in range(4):\n",
    "        data[2008+4*i] = fips_dropper([data[year] for year in data])[i]\n",
    "    \n",
    "    # Sort all merged data sets by FIPS codes\n",
    "    for year in years:\n",
    "        data[year].sort_values(by='fips',inplace=True,ignore_index=True)\n",
    "        \n",
    "    # Add population density by calculating population/area\n",
    "    for year in years:\n",
    "        data[year]['pop_density'] = data[year].pop_tot / data[year].CENSUSAREA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nans():\n",
    "    for year in years:                                                                  # go through each year\n",
    "        nan_dic = find_nan(data[year])                                                  # make dict with key=column names : values=list of row indices with nans\n",
    "        for column in data[year].columns:                                               # go through each column\n",
    "            if len(nan_dic[column])>0:\n",
    "                for nan_row in nan_dic[column]:                                         # check if there's a row with a nan in that column\n",
    "                    values = pd.Series([ data[y].loc[nan_row,column] for y in data ])   # if so, make a series with values for that entry across all four years\n",
    "                    values = values.interpolate().bfill()             # interpolate to fill in the nan value\n",
    "                    for i in range(4):                                      \n",
    "                        data[2008+4*i].loc[nan_row,column] = values[i]                  # replace the values for that row,column across all four years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data to percentage values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percentages():\n",
    "    # Append a Boolean row for classification\n",
    "    # Dem-win = 0 , Repub-win = 1\n",
    "    for year in years:\n",
    "        data[year]['y'] = 0 \n",
    "        for i in range(len(data[year])):\n",
    "            if data[year].loc[i,'repub'] > data[year].loc[i,'dem']:\n",
    "                data[year].loc[i,'y'] = 1\n",
    "\n",
    "    # Append columns with percentage values\n",
    "        new_cols = {'fips' : data[year].fips,\n",
    "                'y' : data[year].y,\n",
    "                'vote_diff%' : (data[year].repub - data[year].dem) / (data[year].repub + data[year].dem),\n",
    "                'vote_prob' : data[year].repub / ( data[year].repub + data[year].dem),\n",
    "                'dem%': data[year].dem/data[year].totalvotes,\n",
    "                'repub%': data[year].repub/data[year].totalvotes,\n",
    "                'third_party%':data[year].other/data[year].totalvotes,\n",
    "                'turnout':data[year].totalvotes/data[year].pop_tot,\n",
    "                'male%':data[year].pop_male/data[year].pop_tot,\n",
    "                'female%':data[year].pop_female/data[year].pop_tot,\n",
    "                'labor%':data[year].labor_total/data[year].pop_tot,\n",
    "                'armed%':data[year].labor_armed/data[year].pop_tot,\n",
    "                'empl%':data[year].labor_employed/data[year].pop_tot,\n",
    "                'unempl%':data[year].labor_unemployed/data[year].pop_tot,\n",
    "                'poverty%':data[year].income_poverty/data[year].pop_tot,\n",
    "                'income_median': data[year].income_median,\n",
    "                'income_percapita': data[year].income_percapita,\n",
    "                'income_10%': data[year]['income_10']/data[year].pop_tot, \n",
    "                'income_10-15%':data[year]['income_10-15']/data[year].pop_tot, \n",
    "                'income_15-25%':data[year]['income_15-25']/data[year].pop_tot, \n",
    "                'income_25%':data[year].income_25/data[year].pop_tot,\n",
    "                'single%': data[year].marital_single/data[year].pop_tot, \n",
    "                'married%':data[year].marital_married/data[year].pop_tot, \n",
    "                'marital_ratio': data[year].marital_single/data[year].marital_married, # switched\n",
    "                'sepdiv%':data[year].marital_sepdiv/data[year].pop_tot, \n",
    "                'widow%':data[year].marital_widow/data[year].pop_tot,\n",
    "                'edu_low%':data[year].edu_low/data[year].pop_tot, \n",
    "                'edu_mid%': data[year].edu_mid/data[year].pop_tot, \n",
    "                'edu_high%': data[year].edu_high/data[year].pop_tot, \n",
    "                'edulow_age18%':data[year].edu_low_age_18/data[year].pop_tot, \n",
    "                'edulow_age45%':data[year].edu_low_age_45/data[year].pop_tot, \n",
    "                'edulow_age65%':data[year].edu_low_age_65/data[year].pop_tot, \n",
    "                'edumid_age18%': data[year].edu_mid_age_18/data[year].pop_tot, \n",
    "                'edumid_age45%': data[year].edu_mid_age_45/data[year].pop_tot, \n",
    "                'edumid_age65%': data[year].edu_mid_age_65/data[year].pop_tot, \n",
    "                'eduhigh_age18%': data[year].edu_high_age_18/data[year].pop_tot, \n",
    "                'eduhigh_age45%': data[year].edu_high_age_45/data[year].pop_tot, \n",
    "                'eduhigh_age65%': data[year].edu_high_age_65/data[year].pop_tot, \n",
    "                'age_18%': data[year].edu_low_age_18/data[year].pop_tot + data[year].edu_mid_age_18/data[year].pop_tot + data[year].edu_high_age_18/data[year].pop_tot,\n",
    "                'age_45%': data[year].edu_low_age_45/data[year].pop_tot + data[year].edu_mid_age_45/data[year].pop_tot + data[year].edu_high_age_45/data[year].pop_tot,\n",
    "                'age_65%': data[year].edu_low_age_65/data[year].pop_tot + data[year].edu_mid_age_65/data[year].pop_tot + data[year].edu_high_age_65/data[year].pop_tot,\n",
    "                'wht%': data[year].race_wht_total/data[year].pop_tot, \n",
    "                'wht_m%': data[year].race_wht_male/data[year].pop_tot, \n",
    "                'wht_f%': data[year].race_wht_female/data[year].pop_tot, \n",
    "                'blk%': data[year].race_blk_total/data[year].pop_tot, \n",
    "                'blk_m%': data[year].race_blk_male/data[year].pop_tot, \n",
    "                'blk_f%': data[year].race_blk_female/data[year].pop_tot, \n",
    "                'other%': data[year].race_other_total/data[year].pop_tot, \n",
    "                'other_m%': data[year].race_other_male/data[year].pop_tot, \n",
    "                'other_f%': data[year].race_other_female/data[year].pop_tot,\n",
    "                'native%':data[year].native_yes/data[year].pop_tot,\n",
    "                'hispanic%':data[year].hispanic/data[year].pop_tot,\n",
    "                'pop_density':data[year].pop_tot / data[year].CENSUSAREA,\n",
    "                'houses_density':data[year].houses_tot / data[year].CENSUSAREA,\n",
    "                'pop_tot': data[year].pop_tot,\n",
    "                'area_sqmiles': data[year].CENSUSAREA}\n",
    "        data[year] = pd.DataFrame(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files():\n",
    "    # Create csv files for each election year\n",
    "    for year in years:\n",
    "        data[year].to_csv(f\"clean_data/data{year}.csv\", index = False)\n",
    "\n",
    "    # Create one csv file with all the years combined\n",
    "    data_with_year = data.copy()\n",
    "\n",
    "    for year in years:\n",
    "        # Add a year column to each dataset\n",
    "        year_col = pd.Series(  np.full( len(data[year]) , year)  )\n",
    "        data_with_year[year]['year'] = year_col\n",
    "\n",
    "    all_years = pd.concat( [data_with_year[year] for year in years] , axis=0, ignore_index=True  )\n",
    "\n",
    "    all_years.to_csv(\"clean_data/all_years.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_in_percentages():\n",
    "    # Create csv files for each election year\n",
    "    for year in years:\n",
    "        data[year].to_csv(f\"clean_data_%/data{year}.csv\", index = False)\n",
    "\n",
    "    # Create one csv file with all the years combined\n",
    "    data_with_year = data.copy()\n",
    "\n",
    "    for year in years:\n",
    "        # Add a year column to each dataset\n",
    "        year_col = pd.Series(  np.full( len(data[year]) , year)  )\n",
    "        data_with_year[year]['year'] = year_col\n",
    "\n",
    "    all_years = pd.concat( [data_with_year[year] for year in years] , axis=0, ignore_index=True  )\n",
    "\n",
    "    all_years.to_csv(\"clean_data_%/all_years.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Merging, and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_2276/3813285347.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  third_parties = election[year][ election[year]['party'] != 'DEMOCRAT'][ election[year]['party'] != 'REPUBLICAN'].index.to_list()\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_2276/3813285347.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  third_parties = election[year][ election[year]['party'] != 'DEMOCRAT'][ election[year]['party'] != 'REPUBLICAN'].index.to_list()\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_2276/3813285347.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  third_parties = election[year][ election[year]['party'] != 'DEMOCRAT'][ election[year]['party'] != 'REPUBLICAN'].index.to_list()\n",
      "/var/folders/26/840b8l353yv58xh3z45hs1tc0000gn/T/ipykernel_2276/3813285347.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  third_parties = election[year][ election[year]['party'] != 'DEMOCRAT'][ election[year]['party'] != 'REPUBLICAN'].index.to_list()\n"
     ]
    }
   ],
   "source": [
    "# Clean election data\n",
    "election_cleaner()\n",
    "# Clean demographic data\n",
    "demo_cleaner()\n",
    "# Clean geographic data\n",
    "geo_cleaner()\n",
    "\n",
    "# Merge election, demographic, and geographic data by year\n",
    "data_merger()\n",
    "# Interpolate to recover any missing values\n",
    "interpolate_nans()\n",
    "\n",
    "# Create files\n",
    "create_files()\n",
    "# Change data to percentages\n",
    "to_percentages()\n",
    "# Create files\n",
    "create_files_in_percentages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
